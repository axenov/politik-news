{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using custom data configuration default\n"
     ]
    }
   ],
   "source": [
    "from nlp import load_dataset\n",
    "dataset = load_dataset('de_politik_news.py', cache_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "def evaluate(model_test, class_test):\n",
    "    accuracy = accuracy_score(class_test, model_test)\n",
    "    f1_micro = f1_score(class_test, model_test, average = 'micro')\n",
    "    f1_macro = f1_score(class_test, model_test, average = 'macro')\n",
    "    report = classification_report(class_test, model_test)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    print(f'F1-micro: {f1_micro}')\n",
    "    print(f'F1-macro: {f1_macro}')\n",
    "    print(f'Report: {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "bert = BertForSequenceClassification.from_pretrained('models/BERT', num_labels=5).bert\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "bert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = []\n",
    "for i in range(len(dataset['test']['text'])):\n",
    "    ids = tokenizer(dataset['test']['text'][i], padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    prediction = bert(**{k: v.to(device) for k, v in ids.items()})[1].cpu().detach()\n",
    "    predictions.append(prediction)\n",
    "np.savetxt('data/test_embeddings.csv', torch.cat(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(dataset['train']['text'])):\n",
    "    ids = tokenizer(dataset['train']['text'][i], padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    prediction = bert(**{k: v.to(device) for k, v in ids.items()})[1].cpu().detach()\n",
    "    predictions.append(prediction)\n",
    "np.savetxt('data/train_embeddings.csv', torch.cat(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.genfromtxt('data/train_embeddings.csv')\n",
    "y_train = dataset['train']['class']\n",
    "\n",
    "X_test = np.genfromtxt('data/test_embeddings.csv')\n",
    "y_test = dataset['test']['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5, min_impurity_decrease = 0.1, \n",
    "                               criterion = \"entropy\", n_estimators =8, \n",
    "                               class_weight='balanced', random_state=0)\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.432012432012432\n",
      "F1-micro: 0.43201243201243206\n",
      "F1-macro: 0.3836674510189971\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "      center       0.28      0.35      0.31      1349\n",
      " center-left       0.59      0.69      0.63      1159\n",
      "center-right       0.45      0.41      0.43      1754\n",
      "    far-left       0.21      0.11      0.14       215\n",
      "   far-right       0.57      0.32      0.41       671\n",
      "\n",
      "    accuracy                           0.43      5148\n",
      "   macro avg       0.42      0.37      0.38      5148\n",
      "weighted avg       0.44      0.43      0.43      5148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('models/BERT/model.bin', 'wb'))\n",
    "model = pickle.load(open('models/BERT/model.bin', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "model = BalancedRandomForestClassifier(max_depth=10, min_impurity_decrease = 0.001, \n",
    "                               criterion = \"gini\", n_estimators=1000,  random_state=0)\n",
    "model = model.fit(embeddings, dataset['train']['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.38966588966588966\n",
      "F1-micro: 0.38966588966588966\n",
      "F1-macro: 0.39975995518118534\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "      center       0.26      0.17      0.21      1349\n",
      " center-left       0.30      0.34      0.32      1159\n",
      "center-right       0.48      0.56      0.52      1754\n",
      "    far-left       0.49      0.63      0.55       215\n",
      "   far-right       0.41      0.39      0.40       671\n",
      "\n",
      "    accuracy                           0.39      5148\n",
      "   macro avg       0.39      0.42      0.40      5148\n",
      "weighted avg       0.38      0.39      0.38      5148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, embeddings_test, class_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "model = EasyEnsembleClassifier(n_estimators=10,  random_state=0)\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3646076146076146\n",
      "F1-micro: 0.36460761460761465\n",
      "F1-macro: 0.3431566460705905\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "      center       0.28      0.54      0.37      1349\n",
      " center-left       0.52      0.46      0.49      1159\n",
      "center-right       0.38      0.23      0.28      1754\n",
      "    far-left       0.23      0.21      0.22       215\n",
      "   far-right       0.60      0.25      0.35       671\n",
      "\n",
      "    accuracy                           0.36      5148\n",
      "   macro avg       0.40      0.34      0.34      5148\n",
      "weighted avg       0.41      0.36      0.36      5148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daksenov/miniconda2/envs/summ/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty = 'l2', C = 0.1, solver = 'saga', random_state=0)\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4201631701631702\n",
      "F1-micro: 0.42016317016317023\n",
      "F1-macro: 0.33893479155053896\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "      center       0.30      0.41      0.35      1349\n",
      " center-left       0.50      0.64      0.56      1159\n",
      "center-right       0.46      0.42      0.44      1754\n",
      "    far-left       0.15      0.03      0.05       215\n",
      "   far-right       0.66      0.20      0.30       671\n",
      "\n",
      "    accuracy                           0.42      5148\n",
      "   macro avg       0.41      0.34      0.34      5148\n",
      "weighted avg       0.44      0.42      0.41      5148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB(var_smoothing=1e-5)\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4188034188034188\n",
      "F1-micro: 0.4188034188034188\n",
      "F1-macro: 0.3637430809340828\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "      center       0.26      0.31      0.28      1349\n",
      " center-left       0.57      0.74      0.64      1159\n",
      "center-right       0.41      0.39      0.40      1754\n",
      "    far-left       0.21      0.08      0.12       215\n",
      "   far-right       0.60      0.28      0.38       671\n",
      "\n",
      "    accuracy                           0.42      5148\n",
      "   macro avg       0.41      0.36      0.36      5148\n",
      "weighted avg       0.42      0.42      0.41      5148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model.predict(X_test), y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
