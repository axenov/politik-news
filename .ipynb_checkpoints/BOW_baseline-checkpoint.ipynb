{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nlp import load_dataset\n",
    "import os\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data_preprocessed/combined'\n",
    "dataset = load_dataset(os.path.join(DATA_FOLDER, 'de_politik_news.py'), cache_dir=os.path.join(DATA_FOLDER, '.de-politic-news'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "for text in dataset['train']['text']:\n",
    "    word_set.update(word_tokenize(text.lower()))\n",
    "for text in dataset['validation']['text']:\n",
    "    word_set.update(word_tokenize(text.lower()))\n",
    "for text in dataset['test']['text']:\n",
    "    word_set.update(word_tokenize(text.lower()))\n",
    "\n",
    "word_dict =  { word : i for i,word in enumerate(list(word_set))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create BOW train vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = lil_matrix((len(dataset['train']['text']), len(word_set)), dtype=np.int8)\n",
    "#embeddings = csr_matrix((len(dataset['train']['text']), len(word_set)), dtype=np.int8)#.toarray()\n",
    "for i, text in enumerate(dataset['train']['text']):\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word in word_dict:\n",
    "            embeddings[i, word_dict[word]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create BOW validation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_valid = lil_matrix((len(dataset['validation']['text']), len(word_set)), dtype=np.int8)\n",
    "for i, text in enumerate(dataset['validation']['text']):\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word in word_dict:\n",
    "            embeddings_valid[i, word_dict[word]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create BOW test vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_test = lil_matrix((len(dataset['test']['text']), len(word_set)), dtype=np.int8)\n",
    "for i, text in enumerate(dataset['test']['text']):\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word in word_dict:\n",
    "            embeddings_test[i, word_dict[word]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 20\n",
    "model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "model = model.fit(embeddings, dataset['train']['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracy on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test = dataset['test']['class']\n",
    "\n",
    "model_test = model.predict(embeddings_test)\n",
    "accuracy = accuracy_score(class_test, model_test)\n",
    "print(f'accuracy: {accuracy}')\n",
    "\n",
    "num_non_equal = 0\n",
    "for label,pred in zip(class_test, model_test.tolist()):\n",
    "    if label!=pred:\n",
    "        num_non_equal +=1\n",
    "        #print(f'{label} {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
